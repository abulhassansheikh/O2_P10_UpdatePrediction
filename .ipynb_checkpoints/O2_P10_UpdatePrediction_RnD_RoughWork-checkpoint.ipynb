{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brand Pulse Dashboard\n",
    "#Import Necessary Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Data\n",
    "PastYearData =pd.read_csv(\"//192.168.2.32/Group/Data Team/Brand_Update_Location/11_Brand_Performance_Analysis/PastYearDataNew.csv\", encoding='utf-8')\t\n",
    "CurrentYearData =pd.read_csv(\"//192.168.2.32/Group/Data Team/Brand_Update_Location/11_Brand_Performance_Analysis/CurrentYearDataNew.csv\", encoding='utf-8')\t\n",
    "\n",
    "#Combine Past and recent years sales data\n",
    "SD = pd.concat([PastYearData, CurrentYearData], ignore_index=True)\n",
    "SDnum = pd.concat([PastYearData, CurrentYearData], ignore_index=True)\n",
    "\n",
    "SkuAddDate =pd.read_csv(\"//192.168.2.32/Group/Data Team/Brand_Update_Location/11_Brand_Performance_Analysis/skuAddDate.csv\", encoding='utf-8')\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Order_Date string to date and extract relevant date values\n",
    "SD['Order_Date'] = pd.to_datetime(SD['Order_Date'], format= \"%d-%b-%y\")\n",
    "SD['OD_Year'] = SD['Order_Date'].dt.strftime('%Y')\n",
    "SD['OD_MonthNum'] = SD['Order_Date'].dt.strftime('%m')\n",
    "SD['OD_MonthLab'] = SD['Order_Date'].dt.strftime('%B')\n",
    "SD['OD_MonthDay'] = SD['Order_Date'].dt.strftime('%d')\n",
    "SD['OD_WeekDay'] = SD['Order_Date'].dt.strftime('%A')\n",
    "SD[\"NetRevenue\"]= SD.Total_Net_Price_CAD_ - SD.Total_Refunded_CAD_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out any blank orderdate values\n",
    "FilterSD =    SD[(SD['Order_Date']!=\"\")\n",
    "           #& (SD['Supplier']==\"\")\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract meta data from SD\n",
    "##Identify all unique brands\n",
    "AllBrands = SD.attribute_set.unique().astype(str)\n",
    "AllBrands = AllBrands[(AllBrands!=\"Discontinued\") & (AllBrands!=\"nan\") ]\n",
    "\n",
    "AllBrands[268]\n",
    "\n",
    "AllSuppliers = SD.Supplier.unique()\n",
    "AllBucketValues = SD.Order_Bucket.unique()\n",
    "\n",
    "#list(SD.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group by Attribute set & year sold, then count number of sales\n",
    "monthlyGroupingN = (FilterSD.groupby([\"attribute_set\", \"OD_MonthNum\", \"OD_MonthDay\"], as_index=False)\n",
    "                ['Order_Date'].\n",
    "                agg({\"count\":\"count\"}).sort_values([\"attribute_set\",\"OD_MonthNum\",\"OD_MonthDay\"] , ascending = True))\n",
    "\n",
    "monthlyGroupingR = (FilterSD.groupby([\"attribute_set\", \"OD_MonthNum\", \"OD_MonthDay\"], as_index=False)\n",
    "                ['NetRevenue'].\n",
    "                agg({\"NetRevenue\":\"sum\"}).sort_values([\"attribute_set\",\"OD_MonthNum\", \"OD_MonthDay\"] , ascending = True))\n",
    "\n",
    "monthlyGroupingAll = monthlyGroupingN.merge(monthlyGroupingR, on=('attribute_set', 'OD_MonthNum', \"OD_MonthDay\")).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "import statistics as st\n",
    "import calendar\n",
    "\n",
    "DueDatePrediction = pd.DataFrame(columns = ['attribute_set',\"MNum\",'Month' , 'Day', \n",
    "                                                \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"June\", \"July\", \"Aug\", \n",
    "                                                \"Sep\", \"Oct\", \"Nov\", \"Dec\",\"TotalOAD\",\"peakDays\", \"test1\"])\n",
    "\n",
    "#def trend(value):\n",
    "        \n",
    "for value in range(len(AllBrands)-1):\n",
    "\n",
    "    brand = AllBrands[value] \n",
    "    BrandYearSS = monthlyGroupingAll[(monthlyGroupingN['attribute_set']==brand)].reset_index(drop=True)\n",
    "\n",
    "    BrandYearSS[\"OverSales\"] =  BrandYearSS[\"count\"] - st.mean(BrandYearSS[\"count\"])\n",
    "    BrandYearSS[\"OverRev\"] = BrandYearSS[\"NetRevenue\"] -  st.mean(BrandYearSS[\"NetRevenue\"]) \n",
    "\n",
    "    OverIdentify = BrandYearSS[(BrandYearSS[\"OverSales\"]>0) & (BrandYearSS[\"OverRev\"]>0)]\n",
    "    OverIdentify_Tally = OverIdentify.groupby([\"OD_MonthNum\"], as_index=False)['OD_MonthNum'].agg({\"OverCounter\":\"count\"})\n",
    "    \n",
    "    OverIdentify_Final = pd.DataFrame({\"OD_MonthNum\":[\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]})\n",
    "    OverIdentify_Final = OverIdentify_Final.merge(OverIdentify_Tally, on=('OD_MonthNum'), how = \"outer\").reset_index(drop=True)\n",
    "    OverIdentify_Final = OverIdentify_Final.fillna(0)\n",
    "             \n",
    "    if len(OverIdentify_Final)>1:\n",
    "    \n",
    "        for m in range(len(OverIdentify_Final)-1):\n",
    "            Base = (OverIdentify_Final.loc[m+1, \"OverCounter\"])\n",
    "            Threshold = (OverIdentify_Final.loc[m, \"OverCounter\"]*1.5)\n",
    "            if Base>Threshold:\n",
    "                if Base>=6:###Consider reducing to 6\n",
    "                    OverIdentify_Final.loc[m, \"test1\"] = \"Update\"\n",
    "                else:\n",
    "                    OverIdentify_Final.loc[m, \"test1\"]  = \"\"\n",
    "            else:\n",
    "                OverIdentify_Final.loc[m, \"test1\"]  = \"\"\n",
    "\n",
    "        FindDup = len(OverIdentify_Final[OverIdentify_Final[\"test1\"]==\"Update\"])\n",
    "        \n",
    "        if FindDup > 0:\n",
    "            if FindDup==1:\n",
    "                OverIdentify_Final[\"test2\"] = OverIdentify_Final[\"test1\"]\n",
    "\n",
    "                WinningMonth = OverIdentify_Final[OverIdentify_Final.test2 == \"Update\"].reset_index(drop=True).loc[0,\"OD_MonthNum\"]\n",
    "                SubsetWinMonth = monthlyGroupingAll[(monthlyGroupingAll.attribute_set== brand) & (monthlyGroupingAll.OD_MonthNum== WinningMonth)].reset_index(drop=True)\n",
    "\n",
    "            elif FindDup>1:\n",
    "                MultiUpdate = OverIdentify_Final[OverIdentify_Final[\"test1\"]==\"Update\"]\n",
    "                MaxMonths = (len(OverIdentify_Final)-1 - MultiUpdate.index[-1])+1\n",
    "                MultiUpdate[\"index\"] = MultiUpdate.index\n",
    "                MultiUpdate = MultiUpdate.reset_index(drop=True)\n",
    "\n",
    "                for s in range(len(MultiUpdate)):\n",
    "                    if s != (len(MultiUpdate)-1):\n",
    "                        IndexVal = MultiUpdate.loc[s,\"index\"]\n",
    "                        MultiUpdate.loc[s, \"Value\"] = sum(OverIdentify_Final.loc[IndexVal+1:(MaxMonths+IndexVal), \"OverCounter\"])\n",
    "                    else: \n",
    "                        IndexVal = MultiUpdate.loc[s,\"index\"]\n",
    "                        MultiUpdate.loc[s, \"Value\"] = sum(OverIdentify_Final.loc[IndexVal+1:(MaxMonths+IndexVal-1), \"OverCounter\"], OverIdentify_Final.loc[0, \"OverCounter\"])                  \n",
    "\n",
    "                WinMonth = MultiUpdate.sort_values(\"Value\", ascending = False).reset_index(drop=True).loc[0,\"index\"]\n",
    "                \n",
    "                for m in range(len(OverIdentify_Final)-1):\n",
    "                    if m == WinMonth:\n",
    "                        OverIdentify_Final.loc[WinMonth, \"test2\"] = \"Update\"\n",
    "                    else:\n",
    "                        OverIdentify_Final.loc[m, \"test2\"]  = \"\"\n",
    "\n",
    "                WinningMonth = OverIdentify_Final[OverIdentify_Final.test2 == \"Update\"].reset_index(drop=True).loc[0,\"OD_MonthNum\"]\n",
    "                SubsetWinMonth = monthlyGroupingAll[(monthlyGroupingAll.attribute_set== brand) & (monthlyGroupingAll.OD_MonthNum== WinningMonth)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "            #Determine the end of peak\n",
    "            count = 0\n",
    "            sumDays = 0\n",
    "            dayCount = 0\n",
    "            \n",
    "            for i in range(int(WinningMonth), len(OverIdentify_Final)):\n",
    "                if i != 12:\n",
    "                    month = OverIdentify_Final.loc[i, \"OD_MonthNum\"]\n",
    "                    days = OverIdentify_Final.loc[i, \"OverCounter\"]\n",
    "                    count = count + 1\n",
    "                    sumDays = sumDays + days\n",
    "                    avg = (sumDays/count)*.75\n",
    "\n",
    "                    if(days >= avg):\n",
    "                        dayCount = dayCount + 30\n",
    "                    else:\n",
    "                        break\n",
    "                elif i == 12:\n",
    "                    month = OverIdentify_Final.loc[0, \"OD_MonthNum\"]\n",
    "                    days = OverIdentify_Final.loc[0, \"OverCounter\"]\n",
    "                    count = count + 1\n",
    "                    sumDays = sumDays + days\n",
    "                    avg = (sumDays/count)*.75\n",
    "\n",
    "                    if(days >= avg):\n",
    "                        dayCount = dayCount + 30\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                \n",
    "            #Determine day of WinningMonth of due date\n",
    "            TextMonth = calendar.month_name[int(WinningMonth)]\n",
    "            MaxCountIndex = SubsetWinMonth[SubsetWinMonth[\"count\"] == (SubsetWinMonth[\"count\"].max())].index[0]\n",
    "            MaxRevIndex = SubsetWinMonth[SubsetWinMonth[\"NetRevenue\"] == (SubsetWinMonth[\"NetRevenue\"].max())].index[0]\n",
    "\n",
    "            if MaxCountIndex == MaxRevIndex:\n",
    "                MaxOfMonth = MaxCountIndex\n",
    "                if MaxOfMonth == len(SubsetWinMonth)-1:\n",
    "                    MinusLast = SubsetWinMonth.loc[0:len(SubsetWinMonth)-2]\n",
    "                    MaxCountIndex = MinusLast[MinusLast[\"count\"] == (MinusLast[\"count\"].max())].index[0]\n",
    "                    MaxRevIndex = MinusLast[MinusLast[\"NetRevenue\"] == (MinusLast[\"NetRevenue\"].max())].index[0]\n",
    "                    if MaxCountIndex == MaxRevIndex:\n",
    "                        MaxOfMonth = MaxCountIndex\n",
    "                        MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "                    else: \n",
    "                        MaxOfMonth = min(MaxCountIndex, MaxRevIndex)\n",
    "                        MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "                else:\n",
    "                    MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "            else: \n",
    "                MaxOfMonth = min(MaxCountIndex, MaxRevIndex)\n",
    "                MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "\n",
    "            MinCountIndex = MinSubset[MinSubset[\"count\"]==MinSubset.loc[MaxOfMonth:, \"count\"].min()].index[-1]\n",
    "            MinRevIndex =   MinSubset[MinSubset[\"NetRevenue\"]==MinSubset.loc[MaxOfMonth:, \"NetRevenue\"].min()].index[-1]    \n",
    "\n",
    "            if MinCountIndex == MinRevIndex:\n",
    "                FinalIndex = MinRevIndex\n",
    "                SubsetWinMonth.loc[FinalIndex,\"DeadLine\"] = \"***\"\n",
    "                WinDay = SubsetWinMonth.loc[FinalIndex, \"OD_MonthDay\"]\n",
    "            else: \n",
    "                FinalIndex = min(MinCountIndex, MinRevIndex)\n",
    "                SubsetWinMonth.loc[FinalIndex,\"DeadLine\"] = \"***\"\n",
    "                WinDay = SubsetWinMonth.loc[FinalIndex, \"OD_MonthDay\"]\n",
    "        else:\n",
    "            TextMonth = \"None\"\n",
    "            WinningMonth = 0\n",
    "            WinDay = 0\n",
    "        \n",
    "    #Formatting Data\n",
    "    AllRecomMon = str()\n",
    "    AllRecomMonRou = OverIdentify_Final[OverIdentify_Final[\"test1\"]==\"Update\"].reset_index(drop = True)\n",
    "    for m in range(len(AllRecomMonRou)):\n",
    "        AllRecomMon = AllRecomMon + calendar.month_name[int(AllRecomMonRou.loc[m,\"OD_MonthNum\"])]+ \"-\"\n",
    "            \n",
    "    OC = OverIdentify_Final[\"OverCounter\"]\n",
    "    TotalOAD = sum(OC)\n",
    "    DueDateData = brand,WinningMonth,TextMonth,WinDay,OC[0],OC[1],OC[2],OC[3],OC[4],OC[5],OC[6],OC[7],OC[8],OC[9],OC[10],OC[11],TotalOAD,dayCount, str(AllRecomMon)\n",
    "    \n",
    "    DueDatePrediction = DueDatePrediction.append(pd.Series(DueDateData, index=DueDatePrediction.columns),  ignore_index=True)\n",
    "    Daydata = DueDatePrediction[[\"attribute_set\",\"peakDays\"]]\n",
    "\n",
    "            #print(\"------------------------\")\n",
    "    #print(brand + \" \" + str(FindDup))\n",
    "            #print(OverIdentify_Final)\n",
    "            #SubsetWinMonth = SubsetWinMonth.fillna(\"\")\n",
    "            #print(DueDatePrediction)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset internal sku, attribute set and order date from SD data frame\n",
    "SoldSkus = pd.DataFrame(SD.internal_sku.unique().astype(str))\n",
    "SoldSkus.columns = [\"internal_sku\"]\n",
    "\n",
    "\n",
    "#Merge SoldSkus with SkuAddDate\n",
    "SoldSkus = pd.merge(SoldSkus, SkuAddDate, how='inner', on=\"internal_sku\")\n",
    "SoldSkus['add_date'] = pd.to_datetime(SoldSkus['add_date'], format= \"%Y-%m-%d\")\n",
    "BrandLabel = SD[[\"internal_sku\", \"attribute_set\"]]\n",
    "SoldSkus = pd.merge(SoldSkus, BrandLabel, how='inner', on=\"internal_sku\").drop_duplicates(keep=False)\n",
    "SoldSkus= SoldSkus.reset_index()\n",
    "\n",
    "for i in range(len(SoldSkus)):\n",
    "    sku = SoldSkus.loc[i,\"internal_sku\"]\n",
    "    Brand = SoldSkus.loc[i,\"attribute_set\"]\n",
    "    AddDate = SoldSkus.loc[i,\"add_date\"]\n",
    "\n",
    "    AllOrderDates = SD[SD[\"internal_sku\"]==sku].Order_Date.sort_values().reset_index().loc[0,\"Order_Date\"]\n",
    "    PeakDayValue = Daydata[Daydata[\"attribute_set\"]==Brand].reset_index().loc[0, \"peakDays\"]\n",
    "    \n",
    "    RevSubset = SD[SD[\"internal_sku\"]==sku][[\"Order_Date\", \"NetRevenue\" ]]\n",
    "    RevSubset[\"SellDistance\"] = abs(RevSubset[\"Order_Date\"]-AddDate).dt.days\n",
    "    RevSubset[\"SellDifference\"] = PeakDayValue -  RevSubset[\"SellDistance\"]     \n",
    "    NewSkuRev = sum(RevSubset[RevSubset[\"SellDifference\"] >= 0][\"NetRevenue\"])\n",
    "    \n",
    "    SoldSkus.loc[i,\"FirstSoldDate\"] = AllOrderDates\n",
    "    SoldSkus.loc[i,\"PeakDayRange\"] = PeakDayValue\n",
    "    SoldSkus.loc[i,\"NewSkuRev\"] = NewSkuRev\n",
    "    \n",
    "    print(SoldSkus.loc[i,\"internal_sku\"], \"         \", NewSkuRev)\n",
    "\n",
    "\n",
    "SoldSkus['DayDiff'] = abs(SoldSkus.FirstSoldDate-SoldSkus.add_date).dt.days\n",
    "\n",
    "\n",
    "for i in range(len(SoldSkus)):\n",
    "    DayDiff = SoldSkus.loc[i,\"DayDiff\"]\n",
    "    pdr = SoldSkus.loc[i,\"PeakDayRange\"]\n",
    "    \n",
    "    if DayDiff <= pdr: \n",
    "        SoldSkus.loc[i, \"UnderPeakDays\"] = 1\n",
    "    else: \n",
    "        SoldSkus.loc[i, \"UnderPeakDays\"] = 0\n",
    "        \n",
    "    if (DayDiff<365):c\n",
    "        SoldSkus.loc[i, \"UnderYear\"] = 1\n",
    "        SoldSkus.loc[i, \"OverYear\"] = 0\n",
    "        \n",
    "        if(DayDiff<180):\n",
    "            SoldSkus.loc[i, \"HalfYear\"] = 1\n",
    "        else:\n",
    "            SoldSkus.loc[i, \"HalfYear\"] = 0\n",
    "    else:\n",
    "        SoldSkus.loc[i, \"UnderYear\"] = 0 \n",
    "        SoldSkus.loc[i, \"OverYear\"] = 1        \n",
    "\n",
    "\n",
    "AvgDays = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                ['DayDiff'].\n",
    "                agg({\"AvgDayDiff\":\"mean\"}).sort_values([\"AvgDayDiff\"] , ascending = True))\n",
    "    \n",
    "TimesSold = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                ['DayDiff'].\n",
    "                agg({\"TimesSold\":\"count\"}).sort_values([\"TimesSold\"] , ascending = True))\n",
    "\n",
    "UnderYear = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                ['UnderYear'].\n",
    "                agg({\"UnderYear\":\"sum\"}))\n",
    "    \n",
    "OverYear = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                ['OverYear'].\n",
    "                agg({\"OverYear\":\"sum\"}))\n",
    "\n",
    "HalfYear = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                ['HalfYear'].\n",
    "                agg({\"HalfYear\":\"sum\"}))\n",
    "\n",
    "UnderPeakDays = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                ['UnderPeakDays'].\n",
    "                agg({\"UnderPeakDays\":\"sum\"}))\n",
    "\n",
    "NewSkuRev = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                ['NewSkuRev'].\n",
    "                agg({\"NewSkuRev\":\"sum\"}))\n",
    "\n",
    "finalskuCount = AvgDays.merge(TimesSold, on=\"attribute_set\" )\n",
    "finalskuCount = finalskuCount.merge(UnderYear, on=\"attribute_set\" )\n",
    "finalskuCount = finalskuCount.merge(OverYear, on=\"attribute_set\" )\n",
    "finalskuCount = finalskuCount.merge(HalfYear, on=\"attribute_set\" )\n",
    "finalskuCount = finalskuCount.merge(UnderPeakDays, on=\"attribute_set\" )\n",
    "finalskuCount = finalskuCount.merge(NewSkuRev, on=\"attribute_set\" )\n",
    "finalskuCount[\"%UnderYear\"] = finalskuCount[\"UnderYear\"] /(finalskuCount[\"OverYear\"] + finalskuCount[\"UnderYear\"])\n",
    "finalskuCount[\"%HalfYear\"] = finalskuCount[\"HalfYear\"] /(finalskuCount[\"OverYear\"] + finalskuCount[\"UnderYear\"])\n",
    "finalskuCount[\"%UnderPeakDays\"] = finalskuCount[\"UnderPeakDays\"] /(finalskuCount[\"OverYear\"] + finalskuCount[\"UnderYear\"])\n",
    "finalskuCount = finalskuCount.sort_values([\"TimesSold\", \"AvgDayDiff\", \"UnderYear\"] , ascending = [False,True, True])\n",
    "#finalskuCount.to_csv (r'\\\\TDOTFS01\\Group\\Data Team\\Abul\\3. Final Folder\\finalskuCount.csv', index = None, header=True)\n",
    "\n",
    "\n",
    "data = SoldSkus[SoldSkus[\"attribute_set\"]==\"Rough Country\"].DayDiff\n",
    "plt.boxplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aquire net revenue for all brands\n",
    "\n",
    "BrandRev = monthlyGroupingAll.groupby(\"attribute_set\")[\"NetRevenue\"].agg(\"sum\")\n",
    "FinalBrandProfile = finalskuCount.merge(BrandRev, on=\"attribute_set\" ).merge(DueDatePrediction, on=\"attribute_set\" )\n",
    "FinalBrandProfile[\"%NewSkuRev\"] = (FinalBrandProfile[\"NewSkuRev\"]/FinalBrandProfile[\"NetRevenue\"])*100\n",
    "FinalBrandProfile[\"%NewSkuRev\"] = (FinalBrandProfile[\"NewSkuRev\"]/FinalBrandProfile[\"NetRevenue\"])*100\n",
    "\n",
    "#Factors to consider when ranking brands for updates\n",
    "NewSkuRev\n",
    "%NewSkuRev\n",
    "MNum\n",
    "Day\n",
    "\n",
    "UpdatePrioritydf = FinalBrandProfile[[\"attribute_set\", \"MNum\", \"Day\", \"NewSkuRev\", \"%NewSkuRev\"]]\n",
    "UpdatePrioritydf[\"MNum\"] = pd.to_numeric(UpdatePrioritydf[\"MNum\"])\n",
    "UpdatePrioritydf[\"Day\"] = pd.to_numeric(UpdatePrioritydf[\"Day\"])\n",
    "UpdatePrioritydf = UpdatePrioritydf[(UpdatePrioritydf[\"NewSkuRev\"]>0) & (UpdatePrioritydf[\"MNum\"] != 0)]\n",
    "\n",
    "UpdatePrioritydf = UpdatePrioritydf.sort_values([\"MNum\", \"Day\", \"NewSkuRev\"], ascending = [True, True, False]).reset_index()\n",
    "UpdatePrioritydf.to_csv (r'\\\\TDOTFS01\\Group\\Data Team\\Abul\\3. Final Folder\\UpdatePrioritydf.csv', index = None, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Order and range brands to minimize revenue loss to determine update time\n",
    "FinalBrandProfile\n",
    "FinalBrandProfile.to_csv (r'\\\\TDOTFS01\\Group\\Data Team\\Abul\\3. Final Folder\\FinalBrandProfile.csv', index = None, header=True)\n",
    "\n",
    "type(\"0\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X#Want to see per given month of the year, which brands should be updated in the given order of how much revenue and orders they get\n",
    "\n",
    "1. Per brand, during which month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "import statistics as st\n",
    "import calendar\n",
    "\n",
    "DueDatePrediction = pd.DataFrame(columns = ['attribute_set',\"MNum\",'Month' , 'Day', \n",
    "                                                \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"June\", \"July\", \"Aug\", \n",
    "                                                \"Sep\", \"Oct\", \"Nov\", \"Dec\",\"TotalOAD\",\"test1\"])\n",
    "\n",
    "def trend(value):\n",
    "    \n",
    "for value in range(len(AllBrands)-1):\n",
    "\n",
    "    brand = AllBrands[value] \n",
    "    BrandYearSS = monthlyGroupingAll[(monthlyGroupingN['attribute_set']==brand)].reset_index(drop=True)\n",
    "\n",
    "    BrandYearSS[\"OverSales\"] =  BrandYearSS[\"count\"] - st.mean(BrandYearSS[\"count\"])\n",
    "    BrandYearSS[\"OverRev\"] = BrandYearSS[\"NetRevenue\"] -  st.mean(BrandYearSS[\"NetRevenue\"]) \n",
    "\n",
    "    OverIdentify = BrandYearSS[(BrandYearSS[\"OverSales\"]>0) & (BrandYearSS[\"OverRev\"]>0)]\n",
    "    OverIdentify_Tally = OverIdentify.groupby([\"OD_MonthNum\"], as_index=False)['OD_MonthNum'].agg({\"OverCounter\":\"count\"})\n",
    "    \n",
    "    OverIdentify_Final = pd.DataFrame({\"OD_MonthNum\":[\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]})\n",
    "    OverIdentify_Final = OverIdentify_Final.merge(OverIdentify_Tally, on=('OD_MonthNum'), how = \"outer\").reset_index(drop=True)\n",
    "    OverIdentify_Final = OverIdentify_Final.fillna(0)\n",
    "             \n",
    "    if len(OverIdentify_Final)>1:\n",
    "    \n",
    "        for m in range(len(OverIdentify_Final)-1):\n",
    "            Base = (OverIdentify_Final.loc[m+1, \"OverCounter\"])\n",
    "            Threshold = (OverIdentify_Final.loc[m, \"OverCounter\"]*1.5)\n",
    "            if Base>Threshold:\n",
    "                if Base>=6:###Consider reducing to 6\n",
    "                    OverIdentify_Final.loc[m, \"test1\"] = \"Update\"\n",
    "                else:\n",
    "                    OverIdentify_Final.loc[m, \"test1\"]  = \"\"\n",
    "            else:\n",
    "                OverIdentify_Final.loc[m, \"test1\"]  = \"\"\n",
    "\n",
    "        FindDup = len(OverIdentify_Final[OverIdentify_Final[\"test1\"]==\"Update\"])\n",
    "        \n",
    "        if FindDup > 0:\n",
    "            if FindDup==1:\n",
    "                OverIdentify_Final[\"test2\"] = OverIdentify_Final[\"test1\"]\n",
    "\n",
    "                WinningMonth = OverIdentify_Final[OverIdentify_Final.test2 == \"Update\"].reset_index(drop=True).loc[0,\"OD_MonthNum\"]\n",
    "                SubsetWinMonth = monthlyGroupingAll[(monthlyGroupingAll.attribute_set== brand) & (monthlyGroupingAll.OD_MonthNum== WinningMonth)].reset_index(drop=True)\n",
    "\n",
    "            elif FindDup>1:\n",
    "                MultiUpdate = OverIdentify_Final[OverIdentify_Final[\"test1\"]==\"Update\"]\n",
    "                MaxMonths = (len(OverIdentify_Final)-1 - MultiUpdate.index[-1])+1\n",
    "                MultiUpdate[\"index\"] = MultiUpdate.index\n",
    "                MultiUpdate = MultiUpdate.reset_index(drop=True)\n",
    "\n",
    "                for s in range(len(MultiUpdate)):\n",
    "                    if s != (len(MultiUpdate)-1):\n",
    "                        IndexVal = MultiUpdate.loc[s,\"index\"]\n",
    "                        MultiUpdate.loc[s, \"Value\"] = sum(OverIdentify_Final.loc[IndexVal+1:(MaxMonths+IndexVal), \"OverCounter\"])\n",
    "                    else: \n",
    "                        IndexVal = MultiUpdate.loc[s,\"index\"]\n",
    "                        MultiUpdate.loc[s, \"Value\"] = sum(OverIdentify_Final.loc[IndexVal+1:(MaxMonths+IndexVal-1), \"OverCounter\"], OverIdentify_Final.loc[0, \"OverCounter\"])                  \n",
    "\n",
    "                WinMonth = MultiUpdate.sort_values(\"Value\", ascending = False).reset_index(drop=True).loc[0,\"index\"]\n",
    "                \n",
    "                for m in range(len(OverIdentify_Final)-1):\n",
    "                    if m == WinMonth:\n",
    "                        OverIdentify_Final.loc[WinMonth, \"test2\"] = \"Update\"\n",
    "                    else:\n",
    "                        OverIdentify_Final.loc[m, \"test2\"]  = \"\"\n",
    "\n",
    "                WinningMonth = OverIdentify_Final[OverIdentify_Final.test2 == \"Update\"].reset_index(drop=True).loc[0,\"OD_MonthNum\"]\n",
    "                SubsetWinMonth = monthlyGroupingAll[(monthlyGroupingAll.attribute_set== brand) & (monthlyGroupingAll.OD_MonthNum== WinningMonth)].reset_index(drop=True)\n",
    "\n",
    "        #Determine day of WinningMonth of due date\n",
    "            TextMonth = calendar.month_name[int(WinningMonth)]\n",
    "            MaxCountIndex = SubsetWinMonth[SubsetWinMonth[\"count\"] == (SubsetWinMonth[\"count\"].max())].index[0]\n",
    "            MaxRevIndex = SubsetWinMonth[SubsetWinMonth[\"NetRevenue\"] == (SubsetWinMonth[\"NetRevenue\"].max())].index[0]\n",
    "\n",
    "            if MaxCountIndex == MaxRevIndex:\n",
    "                MaxOfMonth = MaxCountIndex\n",
    "                if MaxOfMonth == len(SubsetWinMonth)-1:\n",
    "                    MinusLast = SubsetWinMonth.loc[0:len(SubsetWinMonth)-2]\n",
    "                    MaxCountIndex = MinusLast[MinusLast[\"count\"] == (MinusLast[\"count\"].max())].index[0]\n",
    "                    MaxRevIndex = MinusLast[MinusLast[\"NetRevenue\"] == (MinusLast[\"NetRevenue\"].max())].index[0]\n",
    "                    if MaxCountIndex == MaxRevIndex:\n",
    "                        MaxOfMonth = MaxCountIndex\n",
    "                        MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "                    else: \n",
    "                        MaxOfMonth = min(MaxCountIndex, MaxRevIndex)\n",
    "                        MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "                else:\n",
    "                    MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "            else: \n",
    "                MaxOfMonth = min(MaxCountIndex, MaxRevIndex)\n",
    "                MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "\n",
    "            MinCountIndex = MinSubset[MinSubset[\"count\"]==MinSubset.loc[MaxOfMonth:, \"count\"].min()].index[-1]\n",
    "            MinRevIndex =   MinSubset[MinSubset[\"NetRevenue\"]==MinSubset.loc[MaxOfMonth:, \"NetRevenue\"].min()].index[-1]    \n",
    "\n",
    "            if MinCountIndex == MinRevIndex:\n",
    "                FinalIndex = MinRevIndex\n",
    "                SubsetWinMonth.loc[FinalIndex,\"DeadLine\"] = \"***\"\n",
    "                WinDay = SubsetWinMonth.loc[FinalIndex, \"OD_MonthDay\"]\n",
    "            else: \n",
    "                FinalIndex = min(MinCountIndex, MinRevIndex)\n",
    "                SubsetWinMonth.loc[FinalIndex,\"DeadLine\"] = \"***\"\n",
    "                WinDay = SubsetWinMonth.loc[FinalIndex, \"OD_MonthDay\"]\n",
    "        else:\n",
    "            TextMonth = \"None\"\n",
    "            WinningMonth = 0\n",
    "            WinDay = 0\n",
    "        \n",
    "    #Formatting Data\n",
    "    AllRecomMon = str()\n",
    "    AllRecomMonRou = OverIdentify_Final[OverIdentify_Final[\"test1\"]==\"Update\"].reset_index(drop = True)\n",
    "    for m in range(len(AllRecomMonRou)):\n",
    "        AllRecomMon = AllRecomMon + calendar.month_name[int(AllRecomMonRou.loc[m,\"OD_MonthNum\"])]+ \"-\"\n",
    "            \n",
    "    OC = OverIdentify_Final[\"OverCounter\"]\n",
    "    TotalOAD = sum(OC)\n",
    "    DueDateData = brand,WinningMonth,TextMonth,WinDay,OC[0],OC[1],OC[2],OC[3],OC[4],OC[5],OC[6],OC[7],OC[8],OC[9],OC[10],OC[11],TotalOAD,str(AllRecomMon)\n",
    "    \n",
    "    DueDatePrediction = DueDatePrediction.append(pd.Series(DueDateData, index=DueDatePrediction.columns),  ignore_index=True)\n",
    "            \n",
    "            #print(\"------------------------\")\n",
    "    print(brand + \" \" + str(FindDup))\n",
    "            #print(OverIdentify_Final)\n",
    "            #SubsetWinMonth = SubsetWinMonth.fillna(\"\")\n",
    "            #print(DueDatePrediction)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(AllBrands)-1):\n",
    "    trend(i, DueDatePrediction)\n",
    "\n",
    "DueDatePrediction.to_csv (r'\\\\TDOTFS01\\Group\\Data Team\\Abul\\3. Final Folder\\DueDatePrediction.csv', index = None, header=True) \n",
    "#Don't forget to add '.csv' at the end of the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OverIdentify_Final\n",
    "WinningMonth\n",
    "value = 16\n",
    "\n",
    "\n",
    "count = 0\n",
    "sumDays = 0\n",
    "dayCount = 0\n",
    "\n",
    "for i in range(int(WinningMonth), len(OverIdentify_Final)):\n",
    "    if i != 12:\n",
    "        month = OverIdentify_Final.loc[i, \"OD_MonthNum\"]\n",
    "        days = OverIdentify_Final.loc[i, \"OverCounter\"]\n",
    "        count = count + 1\n",
    "        sumDays = sumDays + days\n",
    "        avg = (sumDays/count)*.75\n",
    "\n",
    "        if(days >= avg):\n",
    "            dayCount = dayCount + 30\n",
    "        else:\n",
    "            break\n",
    "    elif i == 12:\n",
    "        month = OverIdentify_Final.loc[0, \"OD_MonthNum\"]\n",
    "        days = OverIdentify_Final.loc[0, \"OverCounter\"]\n",
    "        count = count + 1\n",
    "        sumDays = sumDays + days\n",
    "        avg = (sumDays/count)*.75\n",
    "\n",
    "        if(days >= avg):\n",
    "            dayCount = dayCount + 30\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "print(dayCount)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend(209)\n",
    "value = \"WeatherTech\"\n",
    "value=336\n",
    "brand = AllBrands[26] \n",
    "brand = \"StopTech\"\n",
    "\n",
    "AllBrands.index(1)\n",
    "np.where(AllBrands==\"TowReady\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "brand = AllBrands[2] \n",
    "BrandYearSS = monthlyGroupingAll[(monthlyGroupingN['attribute_set']==brand)].reset_index(drop=True)\n",
    "AllYears = BrandYearSS.OD_Year.unique()\n",
    "year = AllYears[1]\n",
    "\n",
    "pooledTrend = pd.DataFrame(columns = ['year' , 'month', 'type' , 'rank', \"value\"])\n",
    "\n",
    "for y in AllYears:\n",
    "\n",
    "    SingleYear = BrandYearSS[BrandYearSS['OD_Year']==y]\n",
    "    if SingleYear.count()[0] == 12:\n",
    "        \n",
    "        #Sales Calc\n",
    "        totalS = SingleYear['count'].sum()\n",
    "        SingleYear['PerSales'] = (SingleYear['count']/totalS)*100\n",
    "        tms = list((SingleYear.sort_values([\"PerSales\",\"OD_MonthNum\"] , \n",
    "                                      ascending = [False, True]).reset_index(drop=True).iloc[0, 2:4]))\n",
    "        sms = (SingleYear.sort_values([\"PerSales\",\"OD_MonthNum\"] , \n",
    "                                      ascending = [False, True]).reset_index(drop=True).iloc[1, 2:4])\n",
    "        TopmonthS = y, tms[0], \"Sales\", \"Top\", tms[1]\n",
    "        SecmonthS = y, sms[0], \"Sales\", \"Sec\", sms[1] \n",
    "       \n",
    "        #RevCalc\n",
    "        totalR = SingleYear['NetRevenue'].sum()\n",
    "        SingleYear['PerRev'] = (SingleYear['NetRevenue']/totalR)*100\n",
    "        tmr = (SingleYear.sort_values([\"PerRev\",\"OD_MonthNum\"] , \n",
    "                                      ascending = [False, True]).reset_index(drop=True).iloc[0, 2:5])\n",
    "        smr = (SingleYear.sort_values([\"PerRev\",\"OD_MonthNum\"] , \n",
    "                                      ascending = [False, True]).reset_index(drop=True).iloc[1, 2:5])   \n",
    "        TopmonthR = y,tmr[0], \"Rev\", \"Top\", tmr[2]\n",
    "        SecmonthR = y,smr[0], \"Rev\", \"Sec\", smr[2]\n",
    "        \n",
    "        allresults = [pd.Series(TopmonthS, index=pooledTrend.columns ),  \n",
    "                      pd.Series(TopmonthR, index=pooledTrend.columns ),\n",
    "                      pd.Series(SecmonthS, index=pooledTrend.columns ), \n",
    "                      pd.Series(SecmonthR, index=pooledTrend.columns )]\n",
    "\n",
    "        #allresults = [TopmonthS, TopmonthR, SecmonthR, SecmonthS]\n",
    "        pooledTrend = pooledTrend.append(allresults,  ignore_index=True)\n",
    "\n",
    "        \n",
    "Rev = pooledTrend[pooledTrend[\"type\"]==\"Rev\"]\n",
    "Sales = pooledTrend[pooledTrend[\"type\"]==\"Sales\"]\n",
    "\n",
    "\n",
    "(Rev.groupby([\"month\"], as_index=False)\n",
    "                ['value'].\n",
    "                agg({\"RevSum\":\"sum\"}).sort_values([\"month\",\"RevSum\"] , ascending = [True, True]))\n",
    "\n",
    "(Sales.groupby([\"month\"], as_index=False)\n",
    "                ['value'].\n",
    "                agg({\"SalesSum\":\"sum\"}).sort_values([\"month\",\"SalesSum\"] , ascending = [True, True]))\n",
    "\n",
    "pooledTrend.month.value_counts().sort_values()\n",
    "\n",
    "\n",
    "\n",
    "BrandYearSS['count'].iloc[0]\n",
    "\n",
    "pd.Series(BrandYearSS['count']).pct_change()\n",
    "print [100 * (b - a) / a for a, b in zip(BrandYearSS['CumSum'][::1], BrandYearSS['CumSum'][1::1])]\n",
    "\n",
    "BrandFilterSD['PerSales'] =BrandFilterSD.apply(lambda BrandFilterSD: BrandFilterSD.count/total, axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TroubleShooting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

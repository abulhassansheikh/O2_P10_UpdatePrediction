{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining GUI and algorithm with deafult setting set\n",
    "\n",
    "#Import Necessary Packages\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "from tkinter.messagebox import showinfo\n",
    "import time\n",
    "import threading\n",
    "\n",
    "\n",
    "#Program Data\n",
    "Title= \"Update Schedule Predictor\"\n",
    "Author= \"Abul Hassan Sheikh\"\n",
    "Version= \"V1.0\"\n",
    "Date= \"October 2019\"\n",
    "\n",
    "\n",
    "def UpdatePredictor():\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import statistics as st\n",
    "    import calendar\n",
    "    import datetime\n",
    "    import re\n",
    "    import matplotlib.pyplot as plt\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    \n",
    "    global GlobalStatus\n",
    "    global count\n",
    "    GlobalStatus = \"normal\"\n",
    "    if GlobalStatus == \"normal\":\n",
    "        \n",
    "        year = int(get_year.get())\n",
    "        wLimit = int(get_wLimit.get())\n",
    "        dThresh = int(get_dThresh.get())\n",
    "        perChange = int(get_perChange.get())\n",
    "        Reset.config(state=\"normal\")\n",
    "        RunPrediction.config(state=\"disabled\")\n",
    "        PathSelect.config(state=\"disabled\")\n",
    "        get_year.config(state=\"disabled\")\n",
    "        get_wLimit.config(state=\"disabled\")\n",
    "        get_dThresh.config(state=\"disabled\")\n",
    "        R1.config(state=\"disabled\")\n",
    "        R2.config(state=\"disabled\")\n",
    "        R3.config(state=\"disabled\")\n",
    "        R4.config(state=\"disabled\")\n",
    "\n",
    "        ## Loading Data\n",
    "        PastYearData =pd.read_csv(\"//192.168.2.32/Group/Data Team/Brand_Update_Location/11_Brand_Performance_Analysis/PastYearDataNew.csv\", encoding='utf-8')\t\n",
    "        CurrentYearData =pd.read_csv(\"//192.168.2.32/Group/Data Team/Brand_Update_Location/11_Brand_Performance_Analysis/CurrentYearDataNew.csv\", encoding='utf-8')\t\n",
    "        #Combine Past and recent years sales data\n",
    "        SD = pd.concat([PastYearData, CurrentYearData], ignore_index=True)\n",
    "        SDnum = pd.concat([PastYearData, CurrentYearData], ignore_index=True)\n",
    "        SkuAddDate =pd.read_csv(\"//192.168.2.32/Group/Data Team/Brand_Update_Location/11_Brand_Performance_Analysis/skuAddDate.csv\", encoding='utf-8')\t\n",
    "\n",
    "        # Convert Order_Date string to date and extract relevant date values\n",
    "        #https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "        SD['Order_Date'] = pd.to_datetime(SD['Order_Date'], format= \"%d-%b-%y\")\n",
    "        SD['OD_Year'] = SD['Order_Date'].dt.strftime('%Y')\n",
    "        SD['OD_MonthNum'] = SD['Order_Date'].dt.strftime('%m')\n",
    "        SD['OD_MonthLab'] = SD['Order_Date'].dt.strftime('%B')\n",
    "        SD['OD_MonthDay'] = SD['Order_Date'].dt.strftime('%d')\n",
    "        SD['OD_WeekDay'] = SD['Order_Date'].dt.strftime('%A')\n",
    "        SD[\"NetRevenue\"]= SD.Total_Net_Price_CAD_ - SD.Total_Refunded_CAD_\n",
    "\n",
    "        # Filter out any blank orderdate values\n",
    "        FilterSD =    SD[(SD['Order_Date']!=\"\")]\n",
    "\n",
    "        #Extract meta data from SD\n",
    "        ##Identify all unique brands\n",
    "        AllBrands = SD.attribute_set.unique().astype(str)\n",
    "        AllBrands = AllBrands[(AllBrands!=\"Discontinued\") & (AllBrands!=\"nan\") ]\n",
    "        AllSuppliers = SD.Supplier.unique()\n",
    "        AllBucketValues = SD.Order_Bucket.unique()\n",
    "\n",
    "        #Group by Attribute set & year sold, then count number of sales\n",
    "        monthlyGroupingN = (FilterSD.groupby([\"attribute_set\", \"OD_MonthNum\", \"OD_MonthDay\"], as_index=False)\n",
    "                        ['Order_Date'].\n",
    "                        agg({\"count\":\"count\"}).sort_values([\"attribute_set\",\"OD_MonthNum\",\"OD_MonthDay\"] , ascending = True))\n",
    "        monthlyGroupingR = (FilterSD.groupby([\"attribute_set\", \"OD_MonthNum\", \"OD_MonthDay\"], as_index=False)\n",
    "                        ['NetRevenue'].\n",
    "                        agg({\"NetRevenue\":\"sum\"}).sort_values([\"attribute_set\",\"OD_MonthNum\", \"OD_MonthDay\"] , ascending = True))\n",
    "        monthlyGroupingAll = monthlyGroupingN.merge(monthlyGroupingR, on=('attribute_set', 'OD_MonthNum', \"OD_MonthDay\")).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        DueDatePrediction = pd.DataFrame(columns = ['attribute_set',\"MNum\",'Month' , 'Day', \n",
    "                                                        \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"June\", \"July\", \"Aug\", \n",
    "                                                        \"Sep\", \"Oct\", \"Nov\", \"Dec\",\"TotalOAD\",\"peakDays\", \"test1\"])\n",
    "\n",
    "        for value in range(len(AllBrands)-1):\n",
    "\n",
    "            brand = AllBrands[value] \n",
    "            BrandYearSS = monthlyGroupingAll[(monthlyGroupingN['attribute_set']==brand)].reset_index(drop=True)\n",
    "\n",
    "            BrandYearSS[\"OverSales\"] =  BrandYearSS[\"count\"] - st.mean(BrandYearSS[\"count\"])\n",
    "            BrandYearSS[\"OverRev\"] = BrandYearSS[\"NetRevenue\"] -  st.mean(BrandYearSS[\"NetRevenue\"]) \n",
    "\n",
    "            OverIdentify = BrandYearSS[(BrandYearSS[\"OverSales\"]>0) & (BrandYearSS[\"OverRev\"]>0)]\n",
    "            OverIdentify_Tally = OverIdentify.groupby([\"OD_MonthNum\"], as_index=False)['OD_MonthNum'].agg({\"OverCounter\":\"count\"})\n",
    "\n",
    "            OverIdentify_Final = pd.DataFrame({\"OD_MonthNum\":[\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]})\n",
    "            OverIdentify_Final = OverIdentify_Final.merge(OverIdentify_Tally, on=('OD_MonthNum'), how = \"outer\").reset_index(drop=True)\n",
    "            OverIdentify_Final = OverIdentify_Final.fillna(0)\n",
    "\n",
    "            if len(OverIdentify_Final)>1:\n",
    "\n",
    "                for m in range(len(OverIdentify_Final)-1):\n",
    "                    Base = (OverIdentify_Final.loc[m+1, \"OverCounter\"])\n",
    "                    Threshold = (OverIdentify_Final.loc[m, \"OverCounter\"]*1.5)\n",
    "                    if Base>Threshold:\n",
    "                        if Base>=6:###Consider reducing to 6\n",
    "                            OverIdentify_Final.loc[m, \"test1\"] = \"Update\"\n",
    "                        else:\n",
    "                            OverIdentify_Final.loc[m, \"test1\"]  = \"\"\n",
    "                    else:\n",
    "                        OverIdentify_Final.loc[m, \"test1\"]  = \"\"\n",
    "\n",
    "                FindDup = len(OverIdentify_Final[OverIdentify_Final[\"test1\"]==\"Update\"])\n",
    "\n",
    "                if FindDup > 0:\n",
    "                    if FindDup==1:\n",
    "                        OverIdentify_Final[\"test2\"] = OverIdentify_Final[\"test1\"]\n",
    "\n",
    "                        WinningMonth = OverIdentify_Final[OverIdentify_Final.test2 == \"Update\"].reset_index(drop=True).loc[0,\"OD_MonthNum\"]\n",
    "                        SubsetWinMonth = monthlyGroupingAll[(monthlyGroupingAll.attribute_set== brand) & (monthlyGroupingAll.OD_MonthNum== WinningMonth)].reset_index(drop=True)\n",
    "\n",
    "                    elif FindDup>1:\n",
    "                        MultiUpdate = OverIdentify_Final[OverIdentify_Final[\"test1\"]==\"Update\"]\n",
    "                        MaxMonths = (len(OverIdentify_Final)-1 - MultiUpdate.index[-1])+1\n",
    "                        MultiUpdate[\"index\"] = MultiUpdate.index\n",
    "                        MultiUpdate = MultiUpdate.reset_index(drop=True)\n",
    "\n",
    "                        for s in range(len(MultiUpdate)):\n",
    "                            if s != (len(MultiUpdate)-1):\n",
    "                                IndexVal = MultiUpdate.loc[s,\"index\"]\n",
    "                                MultiUpdate.loc[s, \"Value\"] = sum(OverIdentify_Final.loc[IndexVal+1:(MaxMonths+IndexVal), \"OverCounter\"])\n",
    "                            else: \n",
    "                                IndexVal = MultiUpdate.loc[s,\"index\"]\n",
    "                                MultiUpdate.loc[s, \"Value\"] = sum(OverIdentify_Final.loc[IndexVal+1:(MaxMonths+IndexVal-1), \"OverCounter\"], OverIdentify_Final.loc[0, \"OverCounter\"])                  \n",
    "\n",
    "                        WinMonth = MultiUpdate.sort_values(\"Value\", ascending = False).reset_index(drop=True).loc[0,\"index\"]\n",
    "\n",
    "                        for m in range(len(OverIdentify_Final)-1):\n",
    "                            if m == WinMonth:\n",
    "                                OverIdentify_Final.loc[WinMonth, \"test2\"] = \"Update\"\n",
    "                            else:\n",
    "                                OverIdentify_Final.loc[m, \"test2\"]  = \"\"\n",
    "\n",
    "                        WinningMonth = OverIdentify_Final[OverIdentify_Final.test2 == \"Update\"].reset_index(drop=True).loc[0,\"OD_MonthNum\"]\n",
    "                        SubsetWinMonth = monthlyGroupingAll[(monthlyGroupingAll.attribute_set== brand) & (monthlyGroupingAll.OD_MonthNum== WinningMonth)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "                    #Determine the end of peak\n",
    "                    count = 0\n",
    "                    sumDays = 0\n",
    "                    dayCount = 0\n",
    "\n",
    "                    for i in range(int(WinningMonth), len(OverIdentify_Final)):\n",
    "                        if i != 12:\n",
    "                            month = OverIdentify_Final.loc[i, \"OD_MonthNum\"]\n",
    "                            days = OverIdentify_Final.loc[i, \"OverCounter\"]\n",
    "                            count = count + 1\n",
    "                            sumDays = sumDays + days\n",
    "                            avg = (sumDays/count)*.75\n",
    "\n",
    "                            if(days >= avg):\n",
    "                                dayCount = dayCount + 30\n",
    "                            else:\n",
    "                                break\n",
    "                        elif i == 12:\n",
    "                            month = OverIdentify_Final.loc[0, \"OD_MonthNum\"]\n",
    "                            days = OverIdentify_Final.loc[0, \"OverCounter\"]\n",
    "                            count = count + 1\n",
    "                            sumDays = sumDays + days\n",
    "                            avg = (sumDays/count)*.75\n",
    "\n",
    "                            if(days >= avg):\n",
    "                                dayCount = dayCount + 30\n",
    "                            else:\n",
    "                                break\n",
    "\n",
    "\n",
    "                    #Determine day of WinningMonth of due date\n",
    "                    TextMonth = calendar.month_name[int(WinningMonth)]\n",
    "                    MaxCountIndex = SubsetWinMonth[SubsetWinMonth[\"count\"] == (SubsetWinMonth[\"count\"].max())].index[0]\n",
    "                    MaxRevIndex = SubsetWinMonth[SubsetWinMonth[\"NetRevenue\"] == (SubsetWinMonth[\"NetRevenue\"].max())].index[0]\n",
    "\n",
    "                    if MaxCountIndex == MaxRevIndex:\n",
    "                        MaxOfMonth = MaxCountIndex\n",
    "                        if MaxOfMonth == len(SubsetWinMonth)-1:\n",
    "                            MinusLast = SubsetWinMonth.loc[0:len(SubsetWinMonth)-2]\n",
    "                            MaxCountIndex = MinusLast[MinusLast[\"count\"] == (MinusLast[\"count\"].max())].index[0]\n",
    "                            MaxRevIndex = MinusLast[MinusLast[\"NetRevenue\"] == (MinusLast[\"NetRevenue\"].max())].index[0]\n",
    "                            if MaxCountIndex == MaxRevIndex:\n",
    "                                MaxOfMonth = MaxCountIndex\n",
    "                                MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "                            else: \n",
    "                                MaxOfMonth = min(MaxCountIndex, MaxRevIndex)\n",
    "                                MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "                        else:\n",
    "                            MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "                    else: \n",
    "                        MaxOfMonth = min(MaxCountIndex, MaxRevIndex)\n",
    "                        MinSubset = SubsetWinMonth.loc[MaxOfMonth:]\n",
    "\n",
    "                    MinCountIndex = MinSubset[MinSubset[\"count\"]==MinSubset.loc[MaxOfMonth:, \"count\"].min()].index[-1]\n",
    "                    MinRevIndex =   MinSubset[MinSubset[\"NetRevenue\"]==MinSubset.loc[MaxOfMonth:, \"NetRevenue\"].min()].index[-1]    \n",
    "\n",
    "                    if MinCountIndex == MinRevIndex:\n",
    "                        FinalIndex = MinRevIndex\n",
    "                        SubsetWinMonth.loc[FinalIndex,\"DeadLine\"] = \"***\"\n",
    "                        WinDay = SubsetWinMonth.loc[FinalIndex, \"OD_MonthDay\"]\n",
    "                    else: \n",
    "                        FinalIndex = min(MinCountIndex, MinRevIndex)\n",
    "                        SubsetWinMonth.loc[FinalIndex,\"DeadLine\"] = \"***\"\n",
    "                        WinDay = SubsetWinMonth.loc[FinalIndex, \"OD_MonthDay\"]\n",
    "                else:\n",
    "                    TextMonth = \"None\"\n",
    "                    WinningMonth = 0\n",
    "                    WinDay = 0\n",
    "\n",
    "            #Formatting Data\n",
    "            AllRecomMon = str()\n",
    "            AllRecomMonRou = OverIdentify_Final[OverIdentify_Final[\"test1\"]==\"Update\"].reset_index(drop = True)\n",
    "            for m in range(len(AllRecomMonRou)):\n",
    "                AllRecomMon = AllRecomMon + calendar.month_name[int(AllRecomMonRou.loc[m,\"OD_MonthNum\"])]+ \"-\"\n",
    "\n",
    "            OC = OverIdentify_Final[\"OverCounter\"]\n",
    "            TotalOAD = sum(OC)\n",
    "            DueDateData = brand,WinningMonth,TextMonth,WinDay,OC[0],OC[1],OC[2],OC[3],OC[4],OC[5],OC[6],OC[7],OC[8],OC[9],OC[10],OC[11],TotalOAD,dayCount, str(AllRecomMon)\n",
    "\n",
    "            DueDatePrediction = DueDatePrediction.append(pd.Series(DueDateData, index=DueDatePrediction.columns),  ignore_index=True)\n",
    "            Daydata = DueDatePrediction[[\"attribute_set\",\"peakDays\"]]\n",
    "\n",
    "        #subset internal sku, attribute set and order date from SD data frame\n",
    "        SoldSkus = pd.DataFrame(SD.internal_sku.unique().astype(str))\n",
    "        SoldSkus.columns = [\"internal_sku\"]\n",
    "\n",
    "        #Merge SoldSkus with SkuAddDate\n",
    "        SoldSkus = pd.merge(SoldSkus, SkuAddDate, how='inner', on=\"internal_sku\")\n",
    "        SoldSkus['add_date'] = pd.to_datetime(SoldSkus['add_date'], format= \"%Y-%m-%d\")\n",
    "        BrandLabel = SD[[\"internal_sku\", \"attribute_set\"]]\n",
    "        SoldSkus = pd.merge(SoldSkus, BrandLabel, how='inner', on=\"internal_sku\").drop_duplicates(keep=False)\n",
    "        SoldSkus= SoldSkus.reset_index()\n",
    "\n",
    "        for i in range(len(SoldSkus)):\n",
    "            if GlobalStatus == \"normal\":\n",
    "                sku = SoldSkus.loc[i,\"internal_sku\"]\n",
    "                Brand = SoldSkus.loc[i,\"attribute_set\"]\n",
    "                AddDate = SoldSkus.loc[i,\"add_date\"]\n",
    "\n",
    "                AllOrderDates = SD[SD[\"internal_sku\"]==sku].Order_Date.sort_values().reset_index().loc[0,\"Order_Date\"]\n",
    "                PeakDayValue = Daydata[Daydata[\"attribute_set\"]==Brand].reset_index().loc[0, \"peakDays\"]\n",
    "\n",
    "                RevSubset = SD[SD[\"internal_sku\"]==sku][[\"Order_Date\", \"NetRevenue\" ]]\n",
    "                RevSubset[\"SellDistance\"] = abs(RevSubset[\"Order_Date\"]-AddDate).dt.days\n",
    "                RevSubset[\"SellDifference\"] = PeakDayValue -  RevSubset[\"SellDistance\"]     \n",
    "                NewSkuRev = sum(RevSubset[RevSubset[\"SellDifference\"] >= 0][\"NetRevenue\"])\n",
    "\n",
    "                SoldSkus.loc[i,\"FirstSoldDate\"] = AllOrderDates\n",
    "                SoldSkus.loc[i,\"PeakDayRange\"] = PeakDayValue\n",
    "                SoldSkus.loc[i,\"NewSkuRev\"] = NewSkuRev\n",
    "\n",
    "                sData = str(round((i/len(SoldSkus))*100)), \" \", str(SoldSkus.loc[i,\"internal_sku\"]), \" \", str(NewSkuRev)\n",
    "                status_value.set(sData)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        #if GlobalStatus == \"normal\":\n",
    "        SoldSkus['DayDiff'] = abs(SoldSkus.FirstSoldDate-SoldSkus.add_date).dt.days\n",
    "\n",
    "\n",
    "        for i in range(len(SoldSkus)):\n",
    "            DayDiff = SoldSkus.loc[i,\"DayDiff\"]\n",
    "            pdr = SoldSkus.loc[i,\"PeakDayRange\"]\n",
    "\n",
    "            if DayDiff <= pdr: \n",
    "                SoldSkus.loc[i, \"UnderPeakDays\"] = 1\n",
    "            else: \n",
    "                SoldSkus.loc[i, \"UnderPeakDays\"] = 0\n",
    "\n",
    "            if (DayDiff<365):\n",
    "                SoldSkus.loc[i, \"UnderYear\"] = 1\n",
    "                SoldSkus.loc[i, \"OverYear\"] = 0\n",
    "\n",
    "                if(DayDiff<180):\n",
    "                    SoldSkus.loc[i, \"HalfYear\"] = 1\n",
    "                else:\n",
    "                    SoldSkus.loc[i, \"HalfYear\"] = 0\n",
    "            else:\n",
    "                SoldSkus.loc[i, \"UnderYear\"] = 0 \n",
    "                SoldSkus.loc[i, \"OverYear\"] = 1        \n",
    "\n",
    "\n",
    "        AvgDays = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                        ['DayDiff'].\n",
    "                        agg({\"AvgDayDiff\":\"mean\"}).sort_values([\"AvgDayDiff\"] , ascending = True))\n",
    "\n",
    "        TimesSold = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                        ['DayDiff'].\n",
    "                        agg({\"TimesSold\":\"count\"}).sort_values([\"TimesSold\"] , ascending = True))\n",
    "\n",
    "        UnderYear = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                        ['UnderYear'].\n",
    "                        agg({\"UnderYear\":\"sum\"}))\n",
    "\n",
    "        OverYear = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                        ['OverYear'].\n",
    "                        agg({\"OverYear\":\"sum\"}))\n",
    "\n",
    "        HalfYear = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                        ['HalfYear'].\n",
    "                        agg({\"HalfYear\":\"sum\"}))\n",
    "\n",
    "        UnderPeakDays = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                        ['UnderPeakDays'].\n",
    "                        agg({\"UnderPeakDays\":\"sum\"}))\n",
    "\n",
    "        NewSkuRev = (SoldSkus.groupby([\"attribute_set\"], as_index=False)\n",
    "                        ['NewSkuRev'].\n",
    "                        agg({\"NewSkuRev\":\"sum\"}))\n",
    "\n",
    "        finalskuCount = AvgDays.merge(TimesSold, on=\"attribute_set\" )\n",
    "        finalskuCount = finalskuCount.merge(UnderYear, on=\"attribute_set\" )\n",
    "        finalskuCount = finalskuCount.merge(OverYear, on=\"attribute_set\" )\n",
    "        finalskuCount = finalskuCount.merge(HalfYear, on=\"attribute_set\" )\n",
    "        finalskuCount = finalskuCount.merge(UnderPeakDays, on=\"attribute_set\" )\n",
    "        finalskuCount = finalskuCount.merge(NewSkuRev, on=\"attribute_set\" )\n",
    "        finalskuCount[\"%UnderYear\"] = finalskuCount[\"UnderYear\"] /(finalskuCount[\"OverYear\"] + finalskuCount[\"UnderYear\"])\n",
    "        finalskuCount[\"%HalfYear\"] = finalskuCount[\"HalfYear\"] /(finalskuCount[\"OverYear\"] + finalskuCount[\"UnderYear\"])\n",
    "        finalskuCount[\"%UnderPeakDays\"] = finalskuCount[\"UnderPeakDays\"] /(finalskuCount[\"OverYear\"] + finalskuCount[\"UnderYear\"])\n",
    "        finalskuCount = finalskuCount.sort_values([\"TimesSold\", \"AvgDayDiff\", \"UnderYear\"] , ascending = [False,True, True])\n",
    "\n",
    "        #Aquire net revenue for all brands\n",
    "        BrandRev = monthlyGroupingAll.groupby(\"attribute_set\")[\"NetRevenue\"].agg(\"sum\")\n",
    "        FinalBrandProfile = finalskuCount.merge(BrandRev, on=\"attribute_set\" ).merge(DueDatePrediction, on=\"attribute_set\" )\n",
    "        FinalBrandProfile[\"%NewSkuRev\"] = (FinalBrandProfile[\"NewSkuRev\"]/FinalBrandProfile[\"NetRevenue\"])*100\n",
    "        FinalBrandProfile[\"%NewSkuRev\"] = (FinalBrandProfile[\"NewSkuRev\"]/FinalBrandProfile[\"NetRevenue\"])*100\n",
    "\n",
    "        UpdatePrioritydf = FinalBrandProfile[[\"attribute_set\", \"MNum\", \"Day\", \"NewSkuRev\", \"%NewSkuRev\"]]\n",
    "        UpdatePrioritydf[\"MNum\"] = pd.to_numeric(UpdatePrioritydf[\"MNum\"])\n",
    "        UpdatePrioritydf[\"Day\"] = pd.to_numeric(UpdatePrioritydf[\"Day\"])\n",
    "        UpdatePrioritydf = UpdatePrioritydf[(UpdatePrioritydf[\"NewSkuRev\"]>0) & (UpdatePrioritydf[\"MNum\"] != 0)]\n",
    "\n",
    "        UpdatePrioritydf = UpdatePrioritydf.sort_values([\"MNum\", \"Day\", \"NewSkuRev\"], ascending = [True, True, False]).reset_index()\n",
    "        #UpdatePrioritydf.to_csv (r'\\\\192.168.2.32\\Group\\Data Team\\Abul\\3. Final Folder\\UpdatePrioritydf.csv', index = None, header=True)\n",
    "\n",
    "        UpdatePrioritydf.loc[(UpdatePrioritydf[\"MNum\"]==2) & (UpdatePrioritydf[\"Day\"]==29), \"Day\"] = 28\n",
    "        UpdatePrioritydf[\"Year\"] = year\n",
    "        UpdatePrioritydf[\"MNum\"] = UpdatePrioritydf[\"MNum\"].map(\"{:02}\".format)\n",
    "        UpdatePrioritydf[\"Day\"] = UpdatePrioritydf[\"Day\"].map(\"{:02}\".format)\n",
    "\n",
    "        UpdatePrioritydf[\"Year\"] = UpdatePrioritydf[\"Year\"].astype(str)\n",
    "        UpdatePrioritydf[\"MNum\"] = UpdatePrioritydf[\"MNum\"].astype(str)\n",
    "        UpdatePrioritydf[\"Day\"] = UpdatePrioritydf[\"Day\"].astype(str)\n",
    "\n",
    "        UpdatePrioritydf[\"Date\"] = UpdatePrioritydf[\"Year\"]+\"-\"+UpdatePrioritydf[\"MNum\"]+\"-\"+UpdatePrioritydf[\"Day\"] \n",
    "        UpdatePrioritydf[\"Date\"] = pd.to_datetime(UpdatePrioritydf[\"Date\"], format= \"%Y-%m-%d\")\n",
    "        UpdatePrioritydf[\"Weekday\"] = UpdatePrioritydf[\"Date\"].dt.dayofweek\n",
    "        UpdatePrioritydf[\"WeekNum\"] = UpdatePrioritydf[\"Date\"].dt.week\n",
    "        UpdatePrioritydf[\"Ref\"] = 0\n",
    "\n",
    "        for w in reversed(range(53)):\n",
    "            weekBrands = UpdatePrioritydf[UpdatePrioritydf[\"WeekNum\"]==w]\n",
    "            BrandPerWeek = len(weekBrands)\n",
    "            #print(BrandPerWeek)\n",
    "            if(BrandPerWeek > updateLimit):\n",
    "                BrandDiff = BrandPerWeek - updateLimit\n",
    "                MovingBrandList = (list(weekBrands.sort_values(\"NewSkuRev\", ascending = True)\n",
    "                                        .reset_index(drop=True)[0:BrandDiff][\"attribute_set\"]))\n",
    "                UpdatePrioritydf.loc[UpdatePrioritydf[\"attribute_set\"].isin(MovingBrandList), \"WeekNum\"] = w-1\n",
    "            weekBrands = UpdatePrioritydf[UpdatePrioritydf[\"WeekNum\"]==w].sort_values(\"NewSkuRev\", ascending = False).reset_index()\n",
    "            for f in range(len(weekBrands)):\n",
    "                brand = weekBrands[\"attribute_set\"][f]\n",
    "                UpdatePrioritydf.loc[UpdatePrioritydf[\"attribute_set\"]==brand, \"Ref\"] = f\n",
    "\n",
    "        UpdatePrioritydf[\"WeekNum\"] = UpdatePrioritydf[\"WeekNum\"].map(\"{:02}\".format)\n",
    "\n",
    "        UpdateSchedule = pd.DataFrame(data={'Day': 1, 'WeekNum': range(0,53), 'Year': year})\n",
    "        UpdateSchedule[\"Day\"] = UpdateSchedule[\"Day\"].astype(str)\n",
    "        UpdateSchedule[\"WeekNum\"] = UpdateSchedule[\"WeekNum\"].map(\"{:02}\".format).astype(str)\n",
    "        UpdateSchedule[\"Year\"] = UpdateSchedule[\"Year\"].astype(str)\n",
    "\n",
    "        UpdateSchedule[\"Date_temp\"] = UpdateSchedule[\"Day\"]+\"-\"+UpdateSchedule[\"WeekNum\"]+\"-\"+UpdateSchedule[\"Year\"] \n",
    "        UpdateSchedule[\"Date_temp\"] = pd.to_datetime(UpdateSchedule[\"Date_temp\"], format= \"%w-%W-%Y\")\n",
    "        UpdateSchedule[\"Month\"] = UpdateSchedule[\"Date_temp\"].dt.month_name()\n",
    "        UpdateSchedule[\"Date\"] = UpdateSchedule[\"Date_temp\"].dt.day\n",
    "\n",
    "        RankedBrands = UpdatePrioritydf.pivot(index='WeekNum', columns='Ref', values='attribute_set')\n",
    "\n",
    "        UpdateScheduleFinal = (UpdateSchedule\n",
    "                               .merge(RankedBrands, on=('WeekNum'))\n",
    "                               .drop(columns=[\"Day\",\"WeekNum\",\"Year\",\"Date_temp\"])\n",
    "                               .fillna(\"\"))\n",
    "\n",
    "        return(UpdateScheduleFinal)\n",
    "\n",
    "\n",
    "        \n",
    "def startUpdatePredictor():\n",
    "    t1 = threading.Thread(target=UpdatePredictor,daemon=True).start()\n",
    "\n",
    "def Resetfun():\n",
    "    global GlobalStatus\n",
    "    GlobalStatus = \"disable\"\n",
    "    Reset.config(state=\"disabled\")\n",
    "    RunPrediction.config(state=\"normal\")\n",
    "    PathSelect.config(state=\"normal\")\n",
    "    get_year.config(state=\"normal\")\n",
    "    get_wLimit.config(state=\"normal\")\n",
    "    get_dThresh.config(state=\"normal\")\n",
    "    R1.config(state=\"normal\")\n",
    "    R2.config(state=\"normal\")\n",
    "    R3.config(state=\"normal\")\n",
    "    R4.config(state=\"normal\")\n",
    "\n",
    "def FolderSelection():\n",
    "    global Path\n",
    "    Path = filedialog.askdirectory()\n",
    "    SelectedPath.config(text = Path)\n",
    "\n",
    "def Close():\n",
    "    global GlobalStatus\n",
    "    GlobalStatus = \"disable\"\n",
    "    root.destroy()\n",
    "\n",
    "def popup_showinfo():\n",
    "    showinfo(Title, \"Update Prediction Complete\")\n",
    "\n",
    "#Make Main window    \n",
    "root = Tk()\n",
    "\n",
    "#Set Variables\n",
    "get_perChange = IntVar()\n",
    "status_value = StringVar()\n",
    "GlobalStatus = \"Normal\"\n",
    "Path = 'C:/'\n",
    "\n",
    "#Make the frames\n",
    "Frame_1 = Frame(root)\n",
    "Frame_1 .pack()\n",
    "Frame_2 = Frame(root)\n",
    "Frame_2 .pack()\n",
    "Frame_3 = Frame(root)\n",
    "Frame_3 .pack()\n",
    "Frame_4 = Frame(root)\n",
    "Frame_4 .pack()\n",
    "Frame_5 = Frame(root)\n",
    "Frame_5 .pack()\n",
    "\n",
    "get_year = Spinbox(Frame_1, from_=2000, to=2100, width = 4, values = 2019)\n",
    "get_wLimit = Spinbox(Frame_1, from_=1, to=100, width = 2, values = 4)\n",
    "get_dThresh = Spinbox(Frame_1, from_=1, to=99, width = 2, values = 6)\n",
    "\n",
    "year = int(get_year.get())\n",
    "wLimit = int(get_wLimit.get())\n",
    "dThresh = int(get_dThresh.get())\n",
    "\n",
    "#GUI Layout\n",
    "Label(Frame_1, text=\"Parameters:\").pack(side = LEFT)\n",
    "\n",
    "Label(Frame_1, text=\" \").pack(side = LEFT)\n",
    "\n",
    "Label(Frame_1, text=\"Year:\").pack(side = LEFT)\n",
    "get_year.pack(side = LEFT)\n",
    "\n",
    "Label(Frame_1, text=\" \").pack(side = LEFT)\n",
    "\n",
    "Label(Frame_1, text=\"Weekly Limit:\").pack(side = LEFT)\n",
    "get_wLimit.pack(side = LEFT)\n",
    "\n",
    "Label(Frame_1, text=\" \").pack(side = LEFT)\n",
    "\n",
    "Label(Frame_1, text=\"Day Limit:\").pack(side = LEFT)\n",
    "get_dThresh.pack(side = LEFT)\n",
    "\n",
    "Label(Frame_2, text=\"                    \").pack(side = LEFT)\n",
    "\n",
    "Label(Frame_2, text=\"%Change:\").pack(side = LEFT)\n",
    "R1 = Radiobutton(Frame_2, text=\"25%\", variable=get_perChange, value=25)\n",
    "R1.pack(side = LEFT)\n",
    "\n",
    "R2 = Radiobutton(Frame_2, text=\"*50%*\", variable=get_perChange, value=50)\n",
    "R2.select()\n",
    "R2.pack(side = LEFT)\n",
    "\n",
    "R3 = Radiobutton(Frame_2, text=\"75%\", variable=get_perChange, value=75)\n",
    "R3.pack(side = LEFT)\n",
    "\n",
    "R4 = Radiobutton(Frame_2, text=\"100%\", variable=get_perChange, value=100)\n",
    "R4.pack(side = LEFT)\n",
    "\n",
    "PathSelect = Button(Frame_3, text =\"Select Path\", command = FolderSelection)\n",
    "PathSelect.pack(side = LEFT)\n",
    "SelectedPath = Label(Frame_3, text=Path,  width = 45, anchor=\"w\")\n",
    "SelectedPath.pack(side = LEFT)\n",
    "\n",
    "RunPrediction = Button(Frame_4, text =\"Execute\", state=\"normal\", command = startUpdatePredictor)\n",
    "RunPrediction.pack(side = LEFT)\n",
    "\n",
    "Status = Label(Frame_4, textvariable=status_value, width = 42, anchor=W, justify=LEFT)\n",
    "Status.pack(side = LEFT)\n",
    "\n",
    "Reset = Button(Frame_4, text =\"Stop\", state=\"disable\", command = Resetfun)\n",
    "Reset.pack(side = LEFT)\n",
    "\n",
    "\n",
    "root.title(str(Version+\" \"+Title +\" by \"+Author+\" (\"+Date+\")\"))\n",
    "root.protocol('WM_DELETE_WINDOW', Close)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
